\chapter{Summary and Conclusion}\label{conclusion}
\section{Evaluation}\label{evaluation}
Each of the objectives identified in section \ref{evaluationstrategy} have been achieved. These are outlined below:\\[0.5em]

\parindent 0pt
\textbf{Database Scalability}
\begin{addmargin}[2em]{0pt}
The scalability of the databases was evaluated by loading the EMAPA and EMAGE datasets into each data model. This provided one with an insight into how adequate the solutions are in handling a big dataset. Each database indicated that they are more than capable of scaling to meet the necessary requirements; to store and import a large volume of data.\\[0.5em]
\end{addmargin}

\textbf{Schema Implementation Complexity}
\begin{addmargin}[2em]{0pt}
A key attribute of NoSQL technologies is their schema-less characteristics. Removing the strict, rigid, structural boundaries which a relational databases imposes allows one to freely adapt and manipulate ones data model with ease. Specifically so within the document-orientated MongoDB environment. Implementing the MongoDB data model, provides one with a sense of control and flexibility, which I found was lacking using a relational database management system.\\[0.5em]
\end{addmargin}

\textbf{Analytical Insight}
\begin{addmargin}[2em]{0pt}
Many of today's largest, most influential and powerful companies in the world are reaping the rewards of collecting and storing big data successfully. This being said, data is useless if it is unclear or impossible to understand. Having the ability to illustrate and visualise data is a key factor in turning data into value. While each of the solutions evaluated all offer a standard flat file export which everyone is familiar with (CSV or equivalent); only Neo4j, the graph-orientated database delivers a refreshing approach to data visualisation. There is a plethora of third-party applications and programming language APIs which can transform one's data into a visual masterpiece. However, Neo4j uses its property graph model structure, to provide one with an out-of-the-box modelling alternative, to previously accepted industry standard traditions.\\[0.5em]
\end{addmargin}

\parindent 15pt
\textbf{Query Language Capabilities}
\begin{addmargin}[2em]{0pt}
Each solution has its own dedicated query language. They all possess functionality which has become standard for any database management system. Neo4j's query language Cypher, is based on SQL constructs, and therefore shares much of the same functional capabilities. Cassandra is the most like a relational database in terms of structure; facilitates similar querying abilities to SQL. The MongoDB querying syntax is vastly different, however functionally, it is not dissimilar to the other solutions.

The query testing which was undertaken as part of the project, exposed the limitations of the systems. Basic functional querying was achieved for all of the solutions. I was able to retrieve subsets of data, capable of providing satisfactory analytical insight into the underlying dataset. However, these insights were limited. Using the respective systems querying languages, I was only able to implement more complex querying such as gene co-expression and calculating transitive closure for Neo4j and MySQL (using a workaround). Admittedly gene co-expression is specific to a biological dataset, however it does have application in other fields.

Neo4j was the only solution which was able to successfully return the expected output for all of the queries. The first four simplistic queries were completed with ease, and the more complex co-expression and transitive closure queries were also achieved. This was as a result of Neo4j's acyclic graph model which allows one to query the path of a relationship.

It is common knowledge that the expressiveness of MySQL systems is limited. Especially so, when defining recursive queries such as transitive closure. Unlike other relational database systems, such as PostgreSQL and DB2 for example, MySQL does not provide the built-in functionality to complete queries such as these. For example, using PostgreSQL, one has the ability to use the ``RECURSIVE'' modifier in a ``WITH'' query. This feature allows one to accomplish results otherwise not possible in standard legacy SQL systems. The ``RECURSIVE'' modifier can use the output of the ``WITH'' query which allows it to query hierarchical data. This is just one alternative relational database system one can use, however there are others which produce similar results. It is often the case with open source software such as the community-edition of MySQL, that there are limitations to what one can achieve. This is a consideration one must decide upon when selecting a database management system. Ensure that the product can facilitate the needs of the requirements or be forced to pay subscription and maintenance fees for a more advanced product. The rights to MySQL was sold to Oracle in 2008, and since then developmental progress seems to have ground to a halt. There has been just one major software release in the past several years. This is a major problem, as there is no official route for developers to discuss the system with Oracle.

The MongoDB and Cassandra systems were unable to successfully complete all of the devised queries. The systems failed to achieve the required output for calculating transitive closure and determining gene co-expression. One reason for this was due to the fact they lack the querying functionality to bind closely related data. Both have the functional capabilities to join data, but fall short when connecting data recursively. The MongoDB and Cassandra querying languages also can not calculate relational algebra. This restricts their ability to calculate complex queries such as transitive closure. Thus, returning the hierarchical path of a value for example, was not possible using the query language functionality alone.

It is important to note: despite the MongoDB and Cassandra systems failing to complete all of the queries, one should not presume achieving the expected result is an impossibility. There are alternative methods for calculating complex queries in these systems. MongoDB and Cassandra both provide API driver documentation. The APIs are available in popular programming languages such as C, C++, Java, Python and Ruby. Providing an API for software engineers to develop their own application is standard for many software companies; including MongoDB and Cassandra. Thus, with suitable pre-processing or sophisticated application code, both systems would be able to successfully achieve all of the queries. However, as data pre-processing and writing application code was out of scope for this project, the MongoDB and Cassandra systems were unable to complete all of the queries.
\end{addmargin}

\section{Future Work}\label{futurework}
Although this project has been successful in achieving each of its intended research objectives, it could be further developed in a number of ways:

\begin{itemize}
\item Using a larger and more complex dataset will further scrutinise the integrity of the database solutions. While the databases were able to cope with the volume of data, the tests did show signs of weakness.
\item Evaluate a variation of the technologies in this project. The database landscape is vast and there are many more database systems which could be used as a basis for further research. For example, NewSQL which seeks to provide one with the same scalability performance of NoSQL solutions with the benefit from ACID transaction guarantees.
\item Assess the usefulness of the data returned with deeper complexity. Each of the solutions evaluated often rely on third-party applications and add ons to make up for their lack of out-of-the-box functionality. Analysing these tools would enhance the justification of using a selected database system.
\end{itemize}

\section{Critique}\label{critique}
The project mainly focused on the capabilities of the data systems in terms of functional ability for a supplied big dataset. Initially it was my intention to scrutinise the data and analyse its availability in more depth. One of the major challenges faced in storing big data is the usefulness of the data itself. The EMAPA and EMAGE datasets are available in a number of file formats, and a closer look into how the extraction and manipulation process is undertaken would have enhanced the understanding of the dataset as a whole.

\section{Thesis Summary}\label{summary}
I developed four prototype data models using both a relational structured database system and leading NoSQL solutions. The data models were examined to identify their positive and negative aspects, using a real-world dataset from the biological field.

Each of the systems were able to meet the required performance specification for storing a large volume of data. While each solution was more than comfortable for storing the EMAPA and EMAGE datasets, the load times for each varied. Neo4j was exposed to show weakness when importing the data without indexes implemented pre-load. MySQL performed the best during the load tests, which aids the argument that it can handle virtually limitless volumes of data. However, in terms of scalability, MySQL seems to struggle when dealing with multiple operations at any one time. MongoDB's ability to take nearly any data and successfully store it with little fuss, gives rise to the fact that its flexibility is one of the key selling points of the system. There was nothing surprising about the results of the load tests for the Cassandra data model. It had to load a larger volume of data and while it did not produce ground-breaking results, faired averagely.

Much of the project evaluation was focused on the querying functionality each system provides. It seems that database management systems are focused on providing one with the functional requirements to complete basic transactions. Anything more complex is expected to be done using an the APIs available and create an application to model the data in whichever way necessary.

As outlined in section \ref{futurework}, there is scope for taking this project further and in various directions. New technologies are being released constantly, providing one with the ability to collect and store their data in ways which were before not possible. It is important these technologies remain open source as progress within paid services can often stagnate and fail to keep up with the pace of development. Big data is an exciting new challenge. However, to be able to profit from this challenge, one needs to ensure they have the infrastructure and management system in place to deal with such complexities. This project has tested the boundaries of some of the most popular database solutions available. It has provided an insight into the analytical capabilities of both industry standard and new technologies. Further research will enhance the justification of using a NoSQL solution as opposed to a relational database for big data.